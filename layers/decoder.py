from speechbrain.nnet.RNN import AttentionalRNNDecoder
from speechbrain.nnet.normalization import LayerNorm
import torch


class AttentionalRNNDecoderWithLayerNorm(AttentionalRNNDecoder):
    """
    This class override speechbrain.nnet.RNN.AttentionalRNNDecoder
    to add LayerNorm after RNN and Attention block
    """

    def __init__(
            self,
            rnn_out_ln: bool = True,
            attn_out_ln: bool = True,
            *args, **kwargs
    ):
        """
        Arguments
        ---------
        rnn_out_ln : bool
            Use layernorm after rnn block
        attn_out_ln : bool
            Use layernorm after attention block
        *args, **kwargs
            Arguments of super class

            Example
        -------
        >>> enc_states = torch.rand([4, 10, 20])
        >>> wav_len = torch.rand([4])
        >>> inp_tensor = torch.rand([4, 5, 6])
        >>> net = AttentionalRNNDecoder(
        ...     rnn_type="lstm",
        ...     attn_type="content",
        ...     hidden_size=7,
        ...     attn_dim=5,
        ...     num_layers=1,
        ...     enc_dim=20,
        ...     input_size=6,
        ... )
        >>> out_tensor, attn = net(inp_tensor, enc_states, wav_len)
        >>> out_tensor.shape
        torch.Size([4, 5, 7])
        """
        super(AttentionalRNNDecoderWithLayerNorm, self).__init__(*args, **kwargs)
        if rnn_out_ln:
            self.rnn_out_ln = LayerNorm(self.hidden_size)
        if attn_out_ln:
            self.attn_out_ln = LayerNorm(self.hidden_size + self.attn_dim)

    def forward_step(self, inp, hs, c, enc_states, enc_len):
        """One step of forward pass process.

        Arguments
        ---------
        inp : torch.Tensor
            The input of current timestep.
        hs : torch.Tensor or tuple of torch.Tensor
            The cell state for RNN.
        c : torch.Tensor
            The context vector of previous timestep.
        enc_states : torch.Tensor
            The tensor generated by encoder, to be attended.
        enc_len : torch.LongTensor
            The actual length of encoder states.

        Returns
        -------
        dec_out : torch.Tensor
            The output tensor.
        hs : torch.Tensor or tuple of torch.Tensor
            The new cell state for RNN.
        c : torch.Tensor
            The context vector of the current timestep.
        w : torch.Tensor
            The weight of attention.
        """
        cell_inp = torch.cat([inp, c], dim=-1)
        cell_inp = self.drop(cell_inp)
        cell_out, hs = self.rnn(cell_inp, hs)
        if hasattr(self, "rnn_out_ln"):
            cell_out = self.rnn_out_ln(cell_out)  # ln

        c, w = self.attn(enc_states, enc_len, cell_out)
        dec_out = torch.cat([c, cell_out], dim=1)
        if hasattr(self, "attn_out_ln"):
            dec_out = self.attn_out_ln(dec_out)  # ln
        dec_out = self.proj(dec_out)

        return dec_out, hs, c, w


if __name__ == "__main__":
    dec = AttentionalRNNDecoderWithLayerNorm(
        enc_dim=512,
        input_size=128,
        rnn_type="gru",
        hidden_size=512,
        attn_dim=512,
        attn_type="keyvalue",
        num_layers=3,
        scaling=1.0,
        dropout=0.0,
        rnn_out_ln=False,
        attn_out_ln=False,
    )
    inp = torch.rand([2, 10, 128])
    enc = torch.rand([2, 1, 512])
    out, attn = dec.forward(
        inp,
        enc,
        torch.tensor([10, 10])
    )
    print(out.shape)
    print(attn.shape)
